%versi 2 (8-10-2016) 
\chapter{Pendahuluan}
\label{chap:intro}
   
\section{Latar Belakang}
\label{sec:label}

{\it Big data} adalah sebuah istilah yang menggambarkan volume data yang besar, baik data yang terstruktur maupun data yang tidak terstruktur. Data-data tersebut memiliki potensi untuk digali menjadi informasi yang penting. Dalam bidang {\it big data} ada  beberapa tantangan seperti volume data yang besar, kecepatan aliran data yang masuk, dan variasi data dengan format yang berbeda. Tantangan tersebut membuat aplikasi pemrosesan data tradisional  tidak bisa memproses dan menganalisis {\it big data}. Muncul teknologi-teknologi seperti Hadoop dan Spark yang dirancang khusus untuk menangani {\it big data}. 

{\it Big data} akan lebih mudah dianalisis dan diterapkan teknik-teknik {\it data-mining} ketika volume {\it big data} tersebut telah direduksi. Dengan mereduksi data, kita bisa menghemat biaya pengiriman data, {\it disk space}, dan jumlah data yang diproses. Hasil dari reduksi {\it big data} harus bisa mewakili data yang belum direduksi secara akurat. 

Salah satu cara mereduksi data adalah dengan menggunakan algoritma {\it Hierarchical Agglomerative Clustering}. Algoritma tersebut cocok untuk data yang tidak memiliki atribut yang terlalu banyak. Journal ilmiah berjudul {\it Big Data Reduction Technique using Parallel Hierarchical Agglomerative Clustering} menjabarkan algoritma {\it Hierarchical Agglomerative Clustering} berbasis MapReduce pada Hadoop~\cite{veronica:02:bdhca}. Penelitian tersebut membuktikan bahwa data yang direduksi dengan algoritma tersebut bisa mewakili data yang belum direduksi. Algoritma {\it Hierarchical Agglomerative Clustering} bekerja dengan mengubah setiap objek menjadi {\it sub-cluster}. Kemudian, {\it sub-cluster} akan digabung dengan {\it sub-cluster} lainya secara bertahap berdasarkan jarak antara {\it sub-cluster} sampai terbentuknya sebuah \textit{cluster}. {\it Cluster} tersebut akan menjadi akar dari hierarki.

Meskipun hasil reduksi data dengan algoritma {\it Hierarchical Agglomerative Clustering} berbasis MapReduce pada Hadoop dapat mewakili data yang belum direduksi secara akurat, MapReduce pada Hadoop memiliki kekurangan. Hadoop tidak efisien dalam melakukan proses iterasi, {\it intermediate data} tidak dapat disimpan pada memori. Hadoop perlu melakukan penulisan dan pembacaan kepada \textit{disk} di antara setiap tahap Map dan Reduce.

Spark adalah {\it distributed cluster-computing framework} yang bisa menggantikan MapReduce beserta kekurangannya. {\it In-memory processing} pada Spark dapat mengalahkan kecepatan pemrosesan pada Hadoop MapReduce. Karena data disimpan pada RAM, kecepatan pemrosesan akan jauh lebih cepat. Spark membaca data yang akan direduksi dari RAM. Pembacaan data dari RAM akan lebih cepat dibanding disk.

Pada skripsi ini, dibangun sebuah perangkat lunak yang dapat mereduksi {\it big data}. Perangkat lunak tersebut akan dibangun menggunakan \textit{framework} terdistribusi Spark dan mengimplementasikan algoritma {\it Hierarchical Agglomerative Clustering} yang khusus dirancang untuk lingkungan Spark. Perangkat lunak dapat menampilkan hasil reduksi dalam format tabel. Dengan menggunakan Spark, waktu proses reduksi data menjadi lebih cepat dibanding MapReduce.




\section{Rumusan Masalah}
\label{sec:rumusan}
Berdasarkan latar belakang di atas, dapat dibentuk rumusan masalah sebagai berikut:
\begin{enumerate}

\item Bagaimana cara kerja algoritma {\it Hierarchical Agglomerative Clustering} berbasis MapReduce untuk mereduksi {\it big data}?

\item Bagaimana cara mengkustomisasi dan mengimplementasikan algoritma {\it Agglomerative Clustering} pada sistem tersebar Spark?

\item Bagaimana mengukur kinerja hasil dari implementasi dari algoritma {\it Agglomerative Clustering} pada sistem tersebar Spark?

\item Bagaimana cara mempresentasikan data yang telah direduksi?

\end{enumerate}



\section{Tujuan}
\label{sec:tujuan}
Berdasarkan rumusan masalah di atas, tujuan dari penelitian adalah sebagai berikut:
\begin{enumerate}

\item Mempelajari cara kerja algoritma  {\it Hierarchical Agglomerative Clustering} berbasis MapReduce untuk mereduksi {\it big data}.

\item Mengkustomisasi dan mengimplementasikan algoritma {\it Hierarchical Agglomerative Clustering} pada lingkungan Spark.

\item Melakukan eksperimen pada lingkungan sistem tersebar Spark untuk mengukur kinerja algoritma lingkungan Spark.

\item Membuat modul program untuk menginterpretasikan data yang telah direduksi.

\end{enumerate}



\section{Batasan Masalah}
\label{sec:batasan}
Batasan masalah pada skripsi ini adalah sebagai berikut:
\begin{enumerate}

\item Studi literatur Hadoop hanya dilakukan pada dasar dan file system Hadoop yaitu HDFS.

\item Studi literatur Apache Spark hanya mempelajari konsep dasar dari Apache Spark, \textit{Resilient Distributed Dataset} (RDD), dan implementasi algoritma \textit{Hierarchical Agglomerative Clustering} (HAC).

\item Metode reduksi data yang dibahas secara mendalam hanya metode {\it agglomerative clustering}.

\item Algoritma {\it Hierarchical Agglomerative Clustering} diimplementasikan secara paralel pada sistem terdistribusi Spark.

\end{enumerate}


\section{Metodologi}
\label{sec:metlit}
Metodologi yang digunakan dalam pembuatan skripsi ini adalah:
\begin{enumerate}

\item Melakukan studi literatur Hadoop hanya mempelajari konsep dasar dari Hadoop dan \textit{Hadoop Distributed File System} (HDFS).

\item Melakukan studi literatur tentang konsep Apache Spark.

\item Melakukan studi literatur bahasa pemrograman Scala.

\item Melakukan studi literatur tentang algoritma {\it Hierarchical Agglomerative Clustering}.

\item Melakukan instalasi dan konfigurasi Apache Spark.

\item Melakukan eksperimen dengan bahasa pemrograman Scala.

\item Melakukan eksperimen dengan Spark RDD.

\item Melakukan kustomisasi algoritma {\it Hierarchical Agglomerative Clustering} untuk Spark.

\item Mencari dan mengumpulkan data uji coba yang bervolume besar.

\item Merancang dan mengimplementasikan perangkat lunak.

\item Melakukan eksperimen terhadap perangkat lunak dan menganalisis hasil eksperimen.

\item Menulis dokumen skripsi.




\end{enumerate}

\section{Sistematika Pembahasan}
\label{sec:sispem}

Laporan penelitian tersusun ke dalam enam bab secara sistematis sebagai berikut:

\begin{itemize}

\item Bab 1 Pendahuluan\\
Berisi latar belakang, rumusan masalah, tujuan, batasan masalah, metodologi penelitian, dan
sistematika pembahasan.

\item Bab 2 Dasar Teori\\
Berisi dasar teori tentang \textit{big data}, \textit{Hierarchical Agglomerative Clustering}, Hadoop, Spark, dan Scala.

\item Bab 3 Studi dan Eksplorasi Apache Spark\\
Berisi percobaan-percobaan yang dilakukan pada Spark.

\item Bab 4 Analisis dan Perancangan\\
Berisi analisis masalah, diagram alur, \textit{use case} dan skenario, diagram kelas, dan perancangan antarmuka.

\item Bab 5 Implementasi dan Pengujian\\
Berisi implementasi antarmuka perangkat lunak, pengujian eksperimen, dan kesimpulan dari pengujian.

\item Bab 5 Implementasi dan Pengujian\\
Berisi kesimpulan awal sampai akhir penelitian dan saran untuk penelitian selanjutnya.


\end{itemize}


